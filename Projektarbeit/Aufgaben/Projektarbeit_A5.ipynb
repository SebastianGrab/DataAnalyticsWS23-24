{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektarbeit Gruppe 2: Gesundheitsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Bibliotheken\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alter Datensatz\n",
    "# Lokaler Repository Pfad auslesen zum dynamischen Laden unabhängig des Nutzers:\n",
    "path = str(os.getcwd()).replace(\"\\Projektarbeit\\Aufgaben\", \"\")\n",
    "\n",
    "# Lesen der CSV Datei:\n",
    "dataset_old = pd.read_csv(path + '\\smoking_driking_dataset_Ver01.csv')\n",
    "\n",
    "# Umbenennen der Spalten:\n",
    "\n",
    "dataset_old = dataset_old.rename(columns={'sex': 'Geschlecht', 'age': 'Alter', 'height': 'Größe', 'weight': 'Gewicht', 'waistline': 'Hüftumfang', 'sight_left': 'Sehkraft_links', 'sight_right': 'Sehkraft_rechts', 'hear_left': 'Hörkraft_links', 'hear_right': 'Hörkraft_rechts', 'SBP': 'Systolischer Blutdruck', 'DBP': 'Diastolischer Blutdruck', 'BLDS': 'Nüchterner Blutzucker', 'tot_chole': 'Totale Cholesterin', 'HDL_chole': 'HDL_Cholesterin', 'LDL_chole': 'LDL_Cholesterin', 'triglyceride': 'Triglycerid', 'hemoglobin': 'Hämoglobin', 'urine_protein': 'Urin_Proteine', 'serum_creatinine': 'Serum_Kreatinin', 'SGOT_AST': 'SGOT_AST', 'SGOT_ALT': 'SGOT_ALT', 'gamma_GTP': 'gamma_GTP', 'SMK_stat_type_cd': 'Raucher_Status', 'DRK_YN': 'Trinker'})\n",
    "\n",
    "dataset_old = dataset_old[['Gewicht', 'Hüftumfang', 'Systolischer Blutdruck', 'Diastolischer Blutdruck', 'Nüchterner Blutzucker', 'Totale Cholesterin', 'HDL_Cholesterin', 'LDL_Cholesterin', 'Triglycerid', 'Hämoglobin', 'Urin_Proteine', 'Serum_Kreatinin', 'SGOT_ALT', 'gamma_GTP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuer Datensatz\n",
    "path = str(os.getcwd()).replace(\"\\Projektarbeit\\Aufgaben\", \"\")\n",
    "\n",
    "# Lesen der CSV Datei:\n",
    "dataset = pd.read_csv(path + '\\dataset_custom.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anforderungen 5: Clustering\n",
    "\n",
    "Führen Sie mit dem Algorithmus Ihrer Wahl eine Clusteranalyse auf Ihren Daten durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering des ursprünglichen Datasets:\n",
    "\n",
    "kmeans_old = KMeans(n_clusters=5, random_state=0, n_init=1)\n",
    "dataset_old['Cluster'] = kmeans_old.fit_predict(dataset_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 0 Größe:  433278\n",
      "Name: 1 Größe:  216468\n",
      "Name: 2 Größe:  3656\n",
      "Name: 3 Größe:  48095\n",
      "Name: 4 Größe:  289849\n"
     ]
    }
   ],
   "source": [
    "# Ausgabe der Clustergrößen:\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(\"Name:\", i, \"Größe: \", list(kmeans_old.labels_).count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SebastianGrab\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\SebastianGrab\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "# Clustering des neuen Datasets:\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0, n_init=1)\n",
    "dataset['Cluster'] = kmeans.fit_predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 0 Größe:  198220\n",
      "Name: 1 Größe:  197157\n",
      "Name: 2 Größe:  200059\n",
      "Name: 3 Größe:  196513\n",
      "Name: 4 Größe:  199340\n"
     ]
    }
   ],
   "source": [
    "# Ausgabe der Clustergrößen:\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(\"Name:\", i, \"Größe: \", list(kmeans.labels_).count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die erste Ausgabe (alter Datensatz) zeigt ungleich große Cluster. \n",
    "# Deshalb wird der angepasste Datensatz verwendet, der aus unserer Projektmappe resultiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Max Scaler Funktion:\n",
    "\n",
    "\n",
    "def minmax_scale_columns(df):\n",
    "    # Kopie des ursprünglichen DataFrame erstellen, um das Original nicht zu ändern\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # MinMaxScaler erstellen\n",
    "    scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "    \n",
    "    # Jede Spalte skalieren\n",
    "    for column in df.columns:\n",
    "        # Überprüfen, ob es sich um numerische Daten handelt (zum Beispiel nicht um Objekte wie Strings)\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # Spalte skalieren\n",
    "            df_scaled[column] = scaler.fit_transform(df[[column]])\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Geschlecht</th>\n",
       "      <th>Alter</th>\n",
       "      <th>Größe</th>\n",
       "      <th>Gewicht</th>\n",
       "      <th>Hüftumfang</th>\n",
       "      <th>Nüchterner Blutzucker</th>\n",
       "      <th>Totale Cholesterin</th>\n",
       "      <th>HDL_Cholesterin</th>\n",
       "      <th>LDL_Cholesterin</th>\n",
       "      <th>...</th>\n",
       "      <th>BD_normal</th>\n",
       "      <th>BD_Grenzwert_normal</th>\n",
       "      <th>BD_Hypertonie Grad 1</th>\n",
       "      <th>BD_Hypertonie Grad 2</th>\n",
       "      <th>BD_Hypertonie Grad 3</th>\n",
       "      <th>Raucher_nie</th>\n",
       "      <th>Raucher_ehem</th>\n",
       "      <th>Raucher_aktiv</th>\n",
       "      <th>Trinker</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>5.811481</td>\n",
       "      <td>0.894800</td>\n",
       "      <td>0.704408</td>\n",
       "      <td>0.057960</td>\n",
       "      <td>0.244236</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>4.782609</td>\n",
       "      <td>5.740609</td>\n",
       "      <td>0.979444</td>\n",
       "      <td>0.855661</td>\n",
       "      <td>0.066593</td>\n",
       "      <td>0.287222</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.882709</td>\n",
       "      <td>0.458081</td>\n",
       "      <td>0.049328</td>\n",
       "      <td>0.142634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>4.782609</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.846433</td>\n",
       "      <td>0.738980</td>\n",
       "      <td>0.092490</td>\n",
       "      <td>0.201250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>3.043478</td>\n",
       "      <td>5.102764</td>\n",
       "      <td>0.918984</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>0.226651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Geschlecht     Alter     Größe   Gewicht  Hüftumfang  \\\n",
       "0     0.00000         0.0  2.307692  6.666667  4.347826    5.811481   \n",
       "1     0.00001         0.0  1.538462  8.333333  4.782609    5.740609   \n",
       "2     0.00002         0.0  3.076923  5.833333  4.347826    5.882353   \n",
       "3     0.00003         0.0  4.615385  7.500000  4.782609    5.882353   \n",
       "4     0.00004         0.0  4.615385  5.833333  3.043478    5.102764   \n",
       "\n",
       "   Nüchterner Blutzucker  Totale Cholesterin  HDL_Cholesterin  \\\n",
       "0               0.894800            0.704408         0.057960   \n",
       "1               0.979444            0.855661         0.066593   \n",
       "2               0.882709            0.458081         0.049328   \n",
       "3               0.846433            0.738980         0.092490   \n",
       "4               0.918984            0.730337         0.073992   \n",
       "\n",
       "   LDL_Cholesterin  ...  BD_normal  BD_Grenzwert_normal  BD_Hypertonie Grad 1  \\\n",
       "0         0.244236  ...       10.0                  0.0                   0.0   \n",
       "1         0.287222  ...       10.0                  0.0                   0.0   \n",
       "2         0.142634  ...        0.0                  0.0                   0.0   \n",
       "3         0.201250  ...        0.0                  0.0                  10.0   \n",
       "4         0.226651  ...        0.0                 10.0                   0.0   \n",
       "\n",
       "   BD_Hypertonie Grad 2  BD_Hypertonie Grad 3  Raucher_nie  Raucher_ehem  \\\n",
       "0                   0.0                   0.0         10.0           0.0   \n",
       "1                   0.0                   0.0          0.0           0.0   \n",
       "2                   0.0                   0.0         10.0           0.0   \n",
       "3                   0.0                   0.0         10.0           0.0   \n",
       "4                   0.0                   0.0         10.0           0.0   \n",
       "\n",
       "   Raucher_aktiv  Trinker  Cluster  \n",
       "0            0.0     10.0      7.5  \n",
       "1           10.0      0.0      7.5  \n",
       "2            0.0      0.0      7.5  \n",
       "3            0.0      0.0      7.5  \n",
       "4            0.0      0.0      7.5  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skalierung der Daten (0 - 10):\n",
    "\n",
    "data_clustering_scaled = minmax_scale_columns(dataset)\n",
    "\n",
    "data_clustering_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeans_scaled = KMeans(n_clusters=5, random_state=0, n_init=1)\n",
    "data_clustering_scaled['Cluster'] = KMeans_scaled.fit_predict(data_clustering_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 0 Größe:  348431\n",
      "Name: 1 Größe:  174950\n",
      "Name: 2 Größe:  163071\n",
      "Name: 3 Größe:  213950\n",
      "Name: 4 Größe:  90887\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"Name:\", i, \"Größe: \", list(KMeans_scaled.labels_).count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setzen Sie die Parameter des Algorithmus mit Hilfe überwachter oder unüberwachter Evaluationsmethoden. Begründen Sie die Auswahl des Evaluationsalgorithmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Ausgabe der Modellmetriken:\n",
    "\n",
    "def evaluate_clustering_metrics(dataset, kmeans_model):\n",
    "\n",
    "    # Clustering-Evaluierungsmetriken berechnen\n",
    "    hom = metrics.homogeneity_score(dataset['Cluster'], kmeans_model.labels_)\n",
    "    com = metrics.completeness_score(dataset['Cluster'], kmeans_model.labels_)\n",
    "    vmeasure = metrics.v_measure_score(dataset['Cluster'], kmeans_model.labels_)\n",
    "\n",
    "    # Ausgabe der Metriken\n",
    "    print(f\"Homogeneity Score: {hom}\")\n",
    "    print(f\"Completeness Score: {com}\")\n",
    "    print(f\"V-Measure Score: {vmeasure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Trainieren eines KMeans Modell mit Ausgabe von Metriken:\n",
    "\n",
    "def cluster_n_print(dataset, c, r, i):\n",
    "    kmeans = KMeans(n_clusters=c, random_state=r, n_init=i)\n",
    "    dataset['Cluster'] = kmeans.fit_predict(dataset)\n",
    "    print(\"-\" * 40)  # waagerechter Strich oben\n",
    "    print(f\"Inertia: {kmeans.inertia_}\\n\"\n",
    "          f\"n_clusters= {kmeans.n_clusters}\\n\"\n",
    "          f\"random_state= {kmeans.random_state}\\n\"\n",
    "          f\"n_init= {kmeans.n_init}\")\n",
    "    print(\"-\" * 40)  # waagerechter Strich unten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Trainieren eines KMeans Modell mit Ausgabe von Metriken, Modell & Datensatz:\n",
    "\n",
    "def cluster_n_print_ver2(dataset, c, r, i):\n",
    "    kmeans = KMeans(n_clusters=c, random_state=r, n_init=i)\n",
    "    dataset['Cluster'] = kmeans.fit_predict(dataset)\n",
    "    print(\"-\" * 40)  # waagerechter Strich oben\n",
    "    print(\"\\n\")\n",
    "    print(f\"Inertia: {kmeans.inertia_}\\n\"\n",
    "          f\"n_clusters= {kmeans.n_clusters}\\n\"\n",
    "          f\"random_state= {kmeans.random_state}\\n\"\n",
    "          f\"n_init= {kmeans.n_init}\\n\")\n",
    "    print(\"Clustergrößen: \")\n",
    "    for j in range(0,c):\n",
    "      print(\"Name:\", j, \"Größe: \", list(kmeans.labels_).count(j))\n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 40)  # waagerechter Strich unten\n",
    "    return dataset, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Trainieren eines KMeans Modell mit Ausgabe von Metriken, Modell & Datensatz:\n",
    "\n",
    "def cluster_n_print_ver3(dataset, c, r, i):\n",
    "    kmeans = KMeans(init=\"random\", n_clusters=c, random_state=r, n_init=i)\n",
    "    dataset['Cluster'] = kmeans.fit_predict(dataset)\n",
    "    print(\"-\" * 40)  # waagerechter Strich oben\n",
    "    print(\"\\n\")\n",
    "    print(f\"Inertia: {kmeans.inertia_}\\n\"\n",
    "          f\"n_clusters= {kmeans.n_clusters}\\n\"\n",
    "          f\"random_state= {kmeans.random_state}\\n\"\n",
    "          f\"n_init= {kmeans.n_init}\\n\"\n",
    "          f\"init= {kmeans.init}\\n\")\n",
    "    print(\"Clustergrößen: \")\n",
    "    for j in range(0,c):\n",
    "      print(\"Name:\", j, \"Größe: \", list(kmeans.labels_).count(j))\n",
    "    print(\"-\" * 40)  # waagerechter Strich unten\n",
    "    return dataset, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2s = minmax_scale_columns(dataset)\n",
    "data_3s = minmax_scale_columns(dataset)\n",
    "data_4s = minmax_scale_columns(dataset)\n",
    "data_5s = minmax_scale_columns(dataset)\n",
    "data_6s = minmax_scale_columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Inertia: 99826359.5985087\n",
      "n_clusters= 5\n",
      "random_state= 0\n",
      "n_init= 40\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cluster_n_print(data_2s, 5, 0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe verschiedener Random States.\n",
    "# Erkenntnis: Minimale Veränderungen in der Nachkommastelle des Inertia-Wertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Inertia: 99826359.53291523\n",
      "n_clusters= 5\n",
      "random_state= 10\n",
      "n_init= 40\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 99826359.53035544\n",
      "n_clusters= 5\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 99826359.53775859\n",
      "n_clusters= 5\n",
      "random_state= 30\n",
      "n_init= 40\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 99826359.52732927\n",
      "n_clusters= 5\n",
      "random_state= 40\n",
      "n_init= 40\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cluster_n_print(data_3s, 5, 10, 40)\n",
    "cluster_n_print(data_4s, 5, 20, 40)\n",
    "cluster_n_print(data_5s, 5, 30, 40)\n",
    "cluster_n_print(data_6s, 5, 40, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe verschiedener Ramdon States (größere Schritte) und unterschiedliche Anzahl von Cluster.\n",
    "# Erkenntnis: Höhere random States führen zu leicht schlechteren Inertia-Werten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_7s = minmax_scale_columns(dataset)\n",
    "data_8s = minmax_scale_columns(dataset)\n",
    "data_9s = minmax_scale_columns(dataset)\n",
    "data_10s = minmax_scale_columns(dataset)\n",
    "data_11s = minmax_scale_columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 99826360.79521458\n",
      "n_clusters= 5\n",
      "random_state= 150\n",
      "n_init= 40\n",
      "\n",
      "----------------------------------------\n",
      "Name: 0 Größe:  136204\n",
      "Name: 1 Größe:  212872\n",
      "Name: 2 Größe:  174872\n",
      "Name: 3 Größe:  335897\n",
      "Name: 4 Größe:  131444\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 99826360.22542998\n",
      "n_clusters= 5\n",
      "random_state= 1000\n",
      "n_init= 40\n",
      "\n",
      "----------------------------------------\n",
      "Name: 0 Größe:  212872\n",
      "Name: 1 Größe:  131444\n",
      "Name: 2 Größe:  174875\n",
      "Name: 3 Größe:  335897\n",
      "Name: 4 Größe:  136201\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 91667530.20053414\n",
      "n_clusters= 6\n",
      "random_state= 0\n",
      "n_init= 40\n",
      "\n",
      "----------------------------------------\n",
      "Name: 0 Größe:  136203\n",
      "Name: 1 Größe:  174869\n",
      "Name: 2 Größe:  213706\n",
      "Name: 3 Größe:  212704\n",
      "Name: 4 Größe:  122377\n",
      "Name: 5 Größe:  131430\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 109540923.83914171\n",
      "n_clusters= 4\n",
      "random_state= 0\n",
      "n_init= 40\n",
      "\n",
      "----------------------------------------\n",
      "Name: 0 Größe:  335897\n",
      "Name: 1 Größe:  213953\n",
      "Name: 2 Größe:  266489\n",
      "Name: 3 Größe:  174950\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 128759988.98470455\n",
      "n_clusters= 3\n",
      "random_state= 0\n",
      "n_init= 40\n",
      "\n",
      "----------------------------------------\n",
      "Name: 0 Größe:  379404\n",
      "Name: 1 Größe:  342984\n",
      "Name: 2 Größe:  268901\n",
      "----------------------------------------\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_7s, kmeans_7s = cluster_n_print_ver2(data_7s, 5, 150, 40)\n",
    "data_8s, kmeans_8s = cluster_n_print_ver2(data_8s, 5, 1000, 40)\n",
    "data_9s, kmeans_9s = cluster_n_print_ver2(data_9s, 6, 0, 40)\n",
    "data_10s, kmeans_10s = cluster_n_print_ver2(data_10s, 4, 0, 40)\n",
    "data_11s, kmeans_11s = cluster_n_print_ver2(data_11s, 3, 0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_12s = minmax_scale_columns(dataset)\n",
    "data_13s = minmax_scale_columns(dataset)\n",
    "data_14s = minmax_scale_columns(dataset)\n",
    "data_15s = minmax_scale_columns(dataset)\n",
    "data_16s = minmax_scale_columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 91667530.10742143\n",
      "n_clusters= 6\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  212703\n",
      "Name: 1 Größe:  131430\n",
      "Name: 2 Größe:  136202\n",
      "Name: 3 Größe:  213707\n",
      "Name: 4 Größe:  174870\n",
      "Name: 5 Größe:  122377\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 84368412.96475229\n",
      "n_clusters= 7\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  99310\n",
      "Name: 1 Größe:  174917\n",
      "Name: 2 Größe:  213539\n",
      "Name: 3 Größe:  135124\n",
      "Name: 4 Größe:  122377\n",
      "Name: 5 Größe:  131385\n",
      "Name: 6 Größe:  114637\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 78589315.8901342\n",
      "n_clusters= 8\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  213534\n",
      "Name: 1 Größe:  114637\n",
      "Name: 2 Größe:  72726\n",
      "Name: 3 Größe:  99310\n",
      "Name: 4 Größe:  102224\n",
      "Name: 5 Größe:  135096\n",
      "Name: 6 Größe:  122377\n",
      "Name: 7 Größe:  131385\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 72519811.93576938\n",
      "n_clusters= 9\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  63935\n",
      "Name: 1 Größe:  216901\n",
      "Name: 2 Größe:  101567\n",
      "Name: 3 Größe:  124705\n",
      "Name: 4 Größe:  113796\n",
      "Name: 5 Größe:  99310\n",
      "Name: 6 Größe:  63245\n",
      "Name: 7 Größe:  72726\n",
      "Name: 8 Größe:  135104\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Inertia: 55970856.010278754\n",
      "n_clusters= 10\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  216901\n",
      "Name: 1 Größe:  124705\n",
      "Name: 2 Größe:  99310\n",
      "Name: 3 Größe:  135097\n",
      "Name: 4 Größe:  101567\n",
      "Name: 5 Größe:  72726\n",
      "Name: 6 Größe:  57683\n",
      "Name: 7 Größe:  56388\n",
      "Name: 8 Größe:  63920\n",
      "Name: 9 Größe:  62992\n",
      "\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_12s, kmeans_12s = cluster_n_print_ver2(data_12s, 6, 20, 40)\n",
    "data_13s, kmeans_13s = cluster_n_print_ver2(data_13s, 7, 20, 40)\n",
    "data_14s, kmeans_14s = cluster_n_print_ver2(data_14s, 8, 20, 40)\n",
    "data_15s, kmeans_17s = cluster_n_print_ver2(data_15s, 9, 20, 40)\n",
    "data_16s, kmeans_16s = cluster_n_print_ver2(data_15s, 10, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_17s = minmax_scale_columns(dataset)\n",
    "data_18s = minmax_scale_columns(dataset)\n",
    "data_19s = minmax_scale_columns(dataset)\n",
    "data_20s = minmax_scale_columns(dataset)\n",
    "data_21s = minmax_scale_columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "\n",
      "Inertia: 87409829.28286432\n",
      "n_clusters= 5\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "init= random\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  131444\n",
      "Name: 1 Größe:  174867\n",
      "Name: 2 Größe:  212872\n",
      "Name: 3 Größe:  335897\n",
      "Name: 4 Größe:  136209\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Inertia: 99826361.65663448\n",
      "n_clusters= 5\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "init= random\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  136209\n",
      "Name: 1 Größe:  174867\n",
      "Name: 2 Größe:  212872\n",
      "Name: 3 Größe:  131444\n",
      "Name: 4 Größe:  335897\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Inertia: 99826361.65663448\n",
      "n_clusters= 5\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "init= random\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  136209\n",
      "Name: 1 Größe:  174867\n",
      "Name: 2 Größe:  212872\n",
      "Name: 3 Größe:  131444\n",
      "Name: 4 Größe:  335897\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Inertia: 99826361.65663448\n",
      "n_clusters= 5\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "init= random\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  136209\n",
      "Name: 1 Größe:  174867\n",
      "Name: 2 Größe:  212872\n",
      "Name: 3 Größe:  131444\n",
      "Name: 4 Größe:  335897\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Inertia: 99826361.65663448\n",
      "n_clusters= 5\n",
      "random_state= 20\n",
      "n_init= 40\n",
      "init= random\n",
      "\n",
      "Clustergrößen: \n",
      "Name: 0 Größe:  136209\n",
      "Name: 1 Größe:  174867\n",
      "Name: 2 Größe:  212872\n",
      "Name: 3 Größe:  131444\n",
      "Name: 4 Größe:  335897\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_17s, kmeans_17s = cluster_n_print_ver3(data_17s, 5, 20, 40)\n",
    "data_18s, kmeans_18s = cluster_n_print_ver3(data_18s, 5, 20, 40)\n",
    "data_19s, kmeans_19s = cluster_n_print_ver3(data_19s, 5, 20, 40)\n",
    "data_20s, kmeans_20s = cluster_n_print_ver3(data_20s, 5, 20, 40)\n",
    "data_21s, kmeans_21s = cluster_n_print_ver3(data_21s, 5, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modelle/kmeans_best_model.joblib']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(kmeans_17s, 'Modelle/kmeans_best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87409829.28286432"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kmeans_model = joblib.load('Modelle/kmeans_best_model.joblib')\n",
    "loaded_kmeans_model.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten Sie die gebildeten Cluster. Wie gut sind sie intuitiv? Welche Informationen über Ihren Datensatz ziehen Sie daraus? Leiten sich weitere Schritte der Datenbereinigung oder der Datenaufbereitung ab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicht intuiutiv. Zu viele Paramter. Die Cluster sind nicht zu interpretieren. PCA wird dringen benötigt. \n",
    "# Außerdem sind einige Werte nicht detailliert genung um diese sinnvoll zu verwenden. (Siehe Confluence) \n",
    "# Für sinnvolle Cluster sollte im Weiteren der Datensatz beschränkt werden (bspw. in männlich/weiblich getrennt) \n",
    "# und ein sinnvoller Anwenundgsfall erarbeitet werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Können Sie in Ihrem Projektkontext Clustering noch für weitere Zwecke (z.B. Outlier Detection oder Profilerstellung) verwenden? (Dies ist nicht immer der Fall.) Skizzieren Sie ggf. kurz ein mögliches Vorgehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evtl um Raucher anhand von Hämoglobin zu erkennen. Viele Werte erfolgen anhand von Messungen, Blutuntersuchugnen etc. \n",
    "# Bei Abfragen wie Raucher oder Trinker besteht die Gefahr, dass ein Proband nicht wahrheitsgemäß antwortet \n",
    "# um ggf. besser eingestuft zu werden. Anhand von Hämoglobin (korreliert mit Raucher_Status postiv, \n",
    "# als auich mit nicht Raucherstatus negativ).\n",
    "\n",
    "# Dazu alle korrelierenden Faktoren (Geschlecht, Gewicht, Größe, Hüftumfang, Hamoglobin) extrahieren und Clustern lassen. \n",
    "# Dadurch wäre supervised learning möglich und man wäre unabhängig der Aussage eines Probanden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
