{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektarbeit Gruppe 2: Gesundheitsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Bibliotheken\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lokaler Repository Pfad auslesen zum dynamischen Laden unabhängig des Nutzers:\n",
    "path = str(os.getcwd()).replace(\"\\Projektarbeit\\Aufgaben\", \"\")\n",
    "\n",
    "# Lesen der CSV Datei:\n",
    "dataset = pd.read_csv(path + '\\smoking_driking_dataset_Ver01.csv')\n",
    "\n",
    "# Umbenennen der Spalten:\n",
    "\n",
    "dataset = dataset.rename(columns={'sex': 'Geschlecht', 'age': 'Alter', 'height': 'Größe', 'weight': 'Gewicht', 'waistline': 'Hüftumfang', 'sight_left': 'Sehkraft_links', 'sight_right': 'Sehkraft_rechts', 'hear_left': 'Hörkraft_links', 'hear_right': 'Hörkraft_rechts', 'SBP': 'Systolischer Blutdruck', 'DBP': 'Diastolischer Blutdruck', 'BLDS': 'Nüchterner Blutzucker', 'tot_chole': 'Totale Cholesterin', 'HDL_chole': 'HDL_Cholesterin', 'LDL_chole': 'LDL_Cholesterin', 'triglyceride': 'Triglycerid', 'hemoglobin': 'Hemoglobin', 'urine_protein': 'Urin_Proteine', 'serum_creatinine': 'Serum_Kreatinin', 'SGOT_AST': 'SGOT_AST', 'SGOT_ALT': 'SGOT_ALT', 'gamma_GTP': 'gamma_GTP', 'SMK_stat_type_cd': 'Raucher_Status', 'DRK_YN': 'Trinker'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anforderungen 5: Clustering\n",
    "\n",
    "Führen Sie mit dem Algorithmus Ihrer Wahl eine Clusteranalyse auf Ihren Daten durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitierung der Größe des Datasets für das Clustering:\n",
    "\n",
    "dataset_clustering = dataset[['Gewicht', 'Hüftumfang', 'Systolischer Blutdruck', 'Diastolischer Blutdruck', 'Blutleckdetektor', 'Totale Cholesterin', 'HDL_Cholesterin', 'LDL_Cholesterin', 'Triglycerid', 'Hemoglobin', 'Urin_Proteine', 'Serum_Kreatinin', 'SGOT_ALT', 'gamma_GTP']]\n",
    "\n",
    "dataset_clustering.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_5364\\3522435617.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clustering2['Cluster'] = kmeans.fit_predict(data_clustering2)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=0, n_init=1)\n",
    "dataset_clustering['Cluster'] = kmeans.fit_predict(dataset_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 0 Größe:  346911\n",
      "Name: 1 Größe:  142706\n",
      "Name: 2 Größe:  8681\n",
      "Name: 3 Größe:  481984\n",
      "Name: 4 Größe:  11064\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"Name:\", i, \"Größe: \", list(kmeans.labels_).count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scale_columns(df):\n",
    "    # Kopie des ursprünglichen DataFrame erstellen, um das Original nicht zu ändern\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # MinMaxScaler erstellen\n",
    "    scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "    \n",
    "    # Jede Spalte skalieren\n",
    "    for column in df.columns:\n",
    "        # Überprüfen, ob es sich um numerische Daten handelt (zum Beispiel nicht um Objekte wie Strings)\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # Spalte skalieren\n",
    "            df_scaled[column] = scaler.fit_transform(df[[column]])\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustering_scaled = minmax_scale_columns(dataset_clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeans_scaled = KMeans(n_clusters=5, random_state=0, n_init=1)\n",
    "data_clustering_scaled['Cluster'] = KMeans_scaled.fit_predict(data_clustering_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 0 Größe:  188165\n",
      "Name: 1 Größe:  493098\n",
      "Name: 2 Größe:  72682\n",
      "Name: 3 Größe:  158743\n",
      "Name: 4 Größe:  78658\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"Name:\", i, \"Größe: \", list(KMeans_scaled.labels_).count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setzen Sie die Parameter des Algorithmus mit Hilfe überwachter oder unüberwachter Evaluationsmethoden. Begründen Sie die Auswahl des Evaluationsalgorithmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance that has already been trained\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data whose clusters should be evaluated.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the supervised clustering metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inertia\n",
    "    results = [name, kmeans.inertia_]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(data, kmeans.labels_,\n",
    "                                 metric=\"euclidean\")\n",
    "    ]\n",
    "    \n",
    "    # Supervised metrics which require the true labels and cluster\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "    ]\n",
    "    results += [m(labels, kmeans.labels_) for m in clustering_metrics]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\"{:9s}\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\")\n",
    "    print(formatter_result.format(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustering_scaled_2= minmax_scale_columns(dataset_clustering)\n",
    "data_clustering_scaled_3= minmax_scale_columns(dataset_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufrufen der Benchmark mit unserem trainierten kmeans und einer zufälligen Zuweisung (zum Vergleich)\n",
    "# Fügen Sie hier auch Ihren günstigeren random_state von oben ein!\n",
    "\n",
    "print(82 * '_')\n",
    "print('init\\t\\tinertia\\tsil\\thom\\tcom\\tv-meas')\n",
    "\n",
    "# unser kmeans-Modell (zur Sicherheit neu trainieren)\n",
    "kmeans = KMeans(n_clusters=5, n_init=1, random_state=0).fit(data_clustering_scaled_2)\n",
    "data_clustering_scaled_2['Cluster'] = kmeans.fit_predict(data_clustering_scaled_2)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means\", data=data_clustering_scaled_2, labels=data_clustering_scaled_2['Cluster'])\n",
    "\n",
    "# zufällige Cluster-Zuordnung erzeugen\n",
    "kmeans_rand = KMeans(init=\"random\", n_clusters=5, n_init=1, random_state=0).fit(data_clustering_scaled_3)\n",
    "data_clustering_scaled_3['Cluster'] = kmeans_rand.fit_predict(data_clustering_scaled_3)\n",
    "bench_k_means(kmeans=kmeans_rand, name=\"random\", data=data_clustering_scaled_3, labels=data_clustering_scaled_3['Cluster'])\n",
    "\n",
    "print(82 * '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9204631748346761\n",
      "0.8222809907825901\n"
     ]
    }
   ],
   "source": [
    "hom = metrics.homogeneity_score(data_clustering_scaled['Cluster'], KMeans_scaled.labels_)\n",
    "com =  metrics.completeness_score(data_clustering_scaled['Cluster'],kmeans.labels_)\n",
    "vmeasure = metrics.v_measure_score(data_clustering_scaled['Cluster'],kmeans.labels_)\n",
    "\n",
    "print(hom)\n",
    "print(com)\n",
    "print(vmeasure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustering_scaled2 = minmax_scale_columns(dataset_clustering)\n",
    "KMeans_scaled_2 = KMeans(init=\"random\", n_clusters=5, random_state=0, n_init=1)\n",
    "data_clustering_scaled2['Cluster'] = KMeans_scaled_2.fit_predict(data_clustering_scaled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "hom = metrics.homogeneity_score(data_clustering_scaled2['Cluster'], KMeans_scaled_2.labels_)\n",
    "com =  metrics.completeness_score(data_clustering_scaled2['Cluster'],KMeans_scaled_2.labels_)\n",
    "vmeasure = metrics.v_measure_score(data_clustering_scaled2['Cluster'],KMeans_scaled_2.labels_)\n",
    "\n",
    "print(hom)\n",
    "print(com)\n",
    "print(vmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans_scaled_2.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans_scaled.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten Sie die gebildeten Cluster. Wie gut sind sie intuitiv? Welche Informationen über Ihren Datensatz ziehen Sie daraus? Leiten sich weitere Schritte der Datenbereinigung oder der Datenaufbereitung ab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7775566870.575328\n",
      "3153133.3341760817\n",
      "2861637.6694306256\n"
     ]
    }
   ],
   "source": [
    "inertia = kmeans.inertia_\n",
    "inertiaS = kmeansS.inertia_\n",
    "inertiaS2 = kmeansS2.inertia_\n",
    "#sil = metrics.silhouette_score(data_clustering_scaled2,kmeansS2.labels_)\n",
    "#silhouette_score dauert sehr lange zu berechnen\n",
    "print(inertia)\n",
    "print(inertiaS)\n",
    "print(inertiaS2)\n",
    "#print(sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustering_scaled3 = minmax_scale_columns(data_clustering)\n",
    "kmeansS3 = KMeans(init=\"random\", n_clusters=5, random_state=1, n_init=2)\n",
    "data_clustering_scaled3['Cluster'] = kmeansS3.fit_predict(data_clustering_scaled3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859724.498274169\n"
     ]
    }
   ],
   "source": [
    "inertiaS3 = kmeansS3.inertia_\n",
    "print(inertiaS3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Können Sie in Ihrem Projektkontext Clustering noch für weitere Zwecke (z.B. Outlier Detection oder Profilerstellung) verwenden? (Dies ist nicht immer der Fall.) Skizzieren Sie ggf. kurz ein mögliches Vorgehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evtl um Raucher anhand von Hemoglobin zu erkennen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
