{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse von Gesundheitsdaten \n",
    "## Projektarbeit Gruppe 2\n",
    "\n",
    "### Konsolidierung aller benötigten Anforderungen innerhalb unseres Use Cases.\n",
    "\n",
    "Projektteam: Sebastian Grab, Josua Klöble, Imanuel Ricker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Datensatz ist auffindbar unter:\n",
    "\n",
    "https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset\n",
    "\n",
    "\n",
    "\n",
    "Unsere Dokumentation ist auffindbar unter:\n",
    "\n",
    "https://grkconsulting.atlassian.net/l/cp/1v1GPp1w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Bibliotheken\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datentransformation & -exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Daten laden und verstehen\n",
    "\n",
    "In diesem Abschnitt werden die Daten geladen und die Spaltenbezeichnungen geändert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lokaler Repository Pfad auslesen zum dynamischen Laden unabhängig des Nutzers:\n",
    "path = str(os.getcwd()).replace(\"\\Projektarbeit\", \"\")\n",
    "\n",
    "# Lesen der CSV Datei:\n",
    "dataset = pd.read_csv(path + '\\smoking_driking_dataset_Ver01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbenennen der Spalten:\n",
    "\n",
    "dataset = dataset.rename(columns={'sex': 'Geschlecht', 'age': 'Alter', 'height': 'Größe', 'weight': 'Gewicht', 'waistline': 'Hüftumfang', 'sight_left': 'Sehkraft_links', 'sight_right': 'Sehkraft_rechts', 'hear_left': 'Hörkraft_links', 'hear_right': 'Hörkraft_rechts', 'SBP': 'Systolischer Blutdruck', 'DBP': 'Diastolischer Blutdruck', 'BLDS': 'Nüchterner Blutzucker', 'tot_chole': 'Totale Cholesterin', 'HDL_chole': 'HDL_Cholesterin', 'LDL_chole': 'LDL_Cholesterin', 'triglyceride': 'Triglycerid', 'hemoglobin': 'Hämoglobin', 'urine_protein': 'Urin_Proteine', 'serum_creatinine': 'Serum_Kreatinin', 'SGOT_AST': 'SGOT_AST', 'SGOT_ALT': 'SGOT_ALT', 'gamma_GTP': 'gamma_GTP', 'SMK_stat_type_cd': 'Raucher_Status', 'DRK_YN': 'Trinker'})\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Spalten:\n",
    "\n",
    "column_names = dataset.columns.values.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Im beigefügten Dokument finden Sie im Abschnitt \"Datensatz\" eine tabellarische Darstellung der einzelnen Spalten zusammen mit entsprechenden Erläuterungen. Um ein umfassendes Verständnis für den vorliegenden Datensatz zu entwickeln, wird empfohlen, sich mit dieser Tabelle vertraut zu machen. Auch der medizinische Kontext wird ausführlich beleuchtet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Daten transformieren\n",
    "\n",
    "In diesem Abschnitt werden die Datentypen angepasst und neue Spalten hinzugefügt, sodass die weitere Arbeit mit den Daten vereinfacht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalten transfomieren:\n",
    "\n",
    "    # Trinker-Spalte: Y (für Yes) zu 1 & n (für No) zu 0\n",
    "\n",
    "dataset[\"Trinker\"] = dataset[\"Trinker\"] == 'Y'\n",
    "dataset[\"Trinker\"] = dataset[\"Trinker\"].astype(int)\n",
    "\n",
    "\n",
    "    # Encoding des Geschlechts:\n",
    "    # Wert 0 = männlich, Wert 1 = weiblich. \n",
    "        # Negative Korrelationen sprechen dafür, dass Männer dazu neigen eine hohe Ausprägung eines Wertes zu haben. \n",
    "        # Postitve Korrelationen sprechen dafür, dass Frauen dazu neigen eine hohe Ausprägung eines Wertes zu haben.\n",
    "dataset['sex_temp'] = dataset['Geschlecht']\n",
    "dataset['Geschlecht'] = np.where(dataset['sex_temp'] == 'Female', 1, 0)\n",
    "\n",
    "    # Entfernen der ursprünglichen 'Geschlecht'-Spalte:\n",
    "\n",
    "dataset = dataset.drop('sex_temp', axis=1)\n",
    "\n",
    "\n",
    "    # Hörkraft-Spalten: 1 (für normal) bleibt 1 & 2 (für abnormal) zu 0\n",
    "\n",
    "dataset[\"Hörkraft_links\"] = dataset[\"Hörkraft_links\"] == 1\n",
    "dataset[\"Hörkraft_links\"] = dataset[\"Hörkraft_links\"].astype(int)\n",
    "\n",
    "dataset[\"Hörkraft_rechts\"] = dataset[\"Hörkraft_rechts\"] == 1\n",
    "dataset[\"Hörkraft_rechts\"] = dataset[\"Hörkraft_rechts\"].astype(int)\n",
    "\n",
    "\n",
    "    # Hinzufügen einer berechneten Spalte - der Body-Mass-Index:\n",
    "\n",
    "body_mass_index = dataset[\"Gewicht\"].astype(np.float64) / ((dataset[\"Größe\"].astype(np.float64) / 100) * (dataset[\"Größe\"].astype(np.float64) / 100))\n",
    "\n",
    "dataset[\"Body-Mass-Index\"] = round(body_mass_index, 2)\n",
    "\n",
    "\n",
    "    # Hinzufügen einer berechneten Spalte - der mittlere arterielle Blutdruck:\n",
    "\n",
    "MAD = dataset[\"Diastolischer Blutdruck\"] + (( dataset[\"Systolischer Blutdruck\"] - dataset[\"Diastolischer Blutdruck\"] ) * 0.5)\n",
    "\n",
    "dataset[\"Mittlerer arterieller Blutdruck\"] = MAD\n",
    "\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben der Normalisierung der Textspalten konnten wir hier zudem den Body-Mass-Index sowie den mittleren arteriellen Blutdruck berechnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Datenexploration\n",
    "\n",
    "In diesem Abschnitt werden die Daten erneut, tiefergehend, betrachtet, sodass eine erweiterte Datenbereinigung ermöglicht wird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenexploration zur Erkennung von Bereinigungsbedarf:\n",
    "\n",
    "    # Funktion zum Darstellen der Verteilung der Werte einer Spalte:\n",
    "\n",
    "def bar_chart(column):\n",
    "    share = (dataset[column].sort_values().value_counts(sort=False) / len(dataset)) * 100 \n",
    "    plt.figure(figsize=(10, 6)) \n",
    "    share.plot(kind='bar') \n",
    "    plt.xlabel(share) \n",
    "    plt.ylabel('Prozentuale Häufigkeit')\n",
    "    plt.grid(axis='y') \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Funktion zum Darstellen der Korrelation der Werte mehrerer Spalten:\n",
    "\n",
    "def corrmap(columns):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    data = dataset[columns]\n",
    "    heatmap = sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellen der Verteilung der jeweiligen Spalten:\n",
    "\n",
    "column_names = dataset.columns.values.tolist()\n",
    "\n",
    "for column in column_names:\n",
    "    bar_chart(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffällige Datenpunkte:\n",
    "\n",
    "1. Hüftumfang: Wenige Datenpunkte bei 999 cm\n",
    "2. Sehkraft_links: Wenige Datenpunkte bei 9.9 (Verteilung der anderen Werte von 0,1 bis 2,0)\n",
    "3. Sehkraft_rechts: Wenige Datenpunkte bei 9.9 (Verteilung der anderen Werte von 0,1 bis 2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmap(['Body-Mass-Index','Gewicht','Größe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffällige Zusammenhänge:\n",
    "\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Datenbereinigung\n",
    "\n",
    "Auf Basis der Datenexploration lassen sich diese in diesem Abschnitt in ihrer Semantik bereinigen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es gibt 57 Reihen, in denen ein Hüftumfang von 9,99 m angegeben wurde:\n",
    "\n",
    "filtered_dataset = dataset[dataset['Hüftumfang'] == 999]\n",
    "len(filtered_dataset.index)\n",
    "\n",
    "    # Eliminierung der fehlerhaften Reihen:\n",
    "\n",
    "dataset = dataset[dataset['Hüftumfang'] != 999]\n",
    "\n",
    "\n",
    "# Es gibt mehrer Reihen, in denen die Sehkraft 9,9 angegeben wurde. Dies bedeutet, dass der Proband erblindet ist.\n",
    "\n",
    "filtered_dataset = dataset[dataset['Sehkraft_rechts'] == 9.9]\n",
    "len(filtered_dataset.index)\n",
    "\n",
    "filtered_dataset = dataset[dataset['Sehkraft_links'] == 9.9]\n",
    "len(filtered_dataset.index)\n",
    "\n",
    "    # Die Sehkraft-Spalten werden später eliminiert und deshalb nicht bereinigt \n",
    "\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kommentare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Selektion & Engineering\n",
    "\n",
    "Nun können wir die Features selektieren und engineeren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selektion\n",
    "\n",
    "Eliminierung der nicht benötigten Spalten. Eine genauere Erläuterung hierzu findet sich in unserer Dokumentation im Kapitel XY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['Sehkraft_links', 'Sehkraft_rechts', 'Hörkraft_links', 'Hörkraft_rechts', 'Urin_Proteine', 'Serum_Kreatinin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Blutdruck\n",
    "\n",
    "Problem: Bedingungen um Blutdruck einzuteilen können nicht immer erfüllt werden. (Bspw. Sys. Blutdruck normal; Dias. Blutdruck optimal. Daher keine Einordung)\n",
    "\n",
    "Lösungen:\n",
    "\n",
    "    1. Toleranzen einbauen\n",
    "\n",
    "    2. Nach mittlerem Blutdruck gehen\n",
    "\n",
    "    3. Nur Obergrenzen festlegen\n",
    "    \n",
    "    4. Sys. und Dias. Blutdruck eigenständig Einordungen. Anschließend beide Einordungen \"vergleichen\" und Mittlere Einordung nehemen. Eventuell mit Hang zum schlechteren.\n",
    "\n",
    "\n",
    "Ansatz 2 ->\n",
    "\n",
    "BD_optimal --> <=119 / <=79 --> <100\n",
    "BD_normal --> 120 - 129 / 80 - 84 --> >=100 - <106,5\n",
    "BD_Grenzwert_normal --> 130 - 139 / 85 - 89 --> >=106,5 - <111,5\n",
    "BD_Hypertonie Grad 1  --> 140 - 159 / 90 - 99 --> >=111,5 - <129\n",
    "BD_Hypertonie Grad 2  --> 160 - 179 / 100 - 109 --> >=129 - <144\n",
    "BD_Hypertonie Grad 3  --> >179 / >109 --> >=111,5 - >=144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"BD_optimal\"] = dataset['Systolischer Blutdruck']\n",
    "dataset[\"BD_normal\"] = dataset['Systolischer Blutdruck']\n",
    "dataset[\"BD_Grenzwert_normal\"] = dataset['Systolischer Blutdruck']\n",
    "dataset[\"BD_Hypertonie Grad 1\"] = dataset['Systolischer Blutdruck']\n",
    "dataset[\"BD_Hypertonie Grad 2\"] = dataset['Systolischer Blutdruck']\n",
    "dataset[\"BD_Hypertonie Grad 3\"] = dataset['Systolischer Blutdruck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"BD_optimal\"] = (dataset['Mittlerer arterieller Blutdruck'] <100)\n",
    "dataset[\"BD_optimal\"] = dataset[\"BD_optimal\"].astype(int)\n",
    "\n",
    "dataset[\"BD_normal\"] = (dataset['Mittlerer arterieller Blutdruck'] >= 100) & (dataset['Mittlerer arterieller Blutdruck'] < 106.5)\n",
    "dataset[\"BD_normal\"] = dataset[\"BD_normal\"].astype(int) \n",
    "\n",
    "dataset[\"BD_Grenzwert_normal\"] = (dataset['Mittlerer arterieller Blutdruck'] >= 106.5) & (dataset['Mittlerer arterieller Blutdruck'] < 111.5)\n",
    "dataset[\"BD_Grenzwert_normal\"] = dataset[\"BD_Grenzwert_normal\"].astype(int) \n",
    "\n",
    "dataset[\"BD_Hypertonie Grad 1\"] = (dataset['Mittlerer arterieller Blutdruck'] >= 111.5) & (dataset['Mittlerer arterieller Blutdruck'] < 129)\n",
    "dataset[\"BD_Hypertonie Grad 1\"] = dataset[\"BD_Hypertonie Grad 1\"].astype(int) \n",
    "\n",
    "dataset[\"BD_Hypertonie Grad 2\"] = (dataset['Mittlerer arterieller Blutdruck'] >= 129) & (dataset['Mittlerer arterieller Blutdruck'] < 144)\n",
    "dataset[\"BD_Hypertonie Grad 2\"] = dataset[\"BD_Hypertonie Grad 2\"].astype(int) \n",
    "\n",
    "dataset[\"BD_Hypertonie Grad 3\"] = (dataset['Mittlerer arterieller Blutdruck'] >=144)\n",
    "dataset[\"BD_Hypertonie Grad 3\"] = dataset[\"BD_Hypertonie Grad 3\"].astype(int) \n",
    "\n",
    "\n",
    "dataset = dataset.drop(columns=['Mittlerer arterieller Blutdruck', 'Systolischer Blutdruck', 'Diastolischer Blutdruck'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raucherstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Raucher_nie'] = np.where(dataset['Raucher_Status'] == 1, 1, 0)\n",
    "dataset['Raucher_ehem'] = np.where(dataset['Raucher_Status'] == 2, 1, 0)\n",
    "dataset['Raucher_aktiv'] = np.where(dataset['Raucher_Status'] == 3, 1, 0)\n",
    "\n",
    "dataset = dataset.drop(columns=['Raucher_Status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={'Trinker': 'Trinker1'})\n",
    "dataset['Trinker'] = dataset['Trinker1']\n",
    "dataset = dataset.drop(columns='Trinker1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speichern des neuen Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des Datasets als CSV:\n",
    "\n",
    "# dataset.to_csv('../dataset_custom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesen der neuen CSV Datei:\n",
    "\n",
    "dataset = pd.read_csv(path + '\\dataset_custom.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Untersuchung der Korrelation aller Features:\n",
    "\n",
    "corrmap(dataset.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anmerkungen: \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
